# Per-Sensor Approach as Default Implementation

## Summary

The per-sensor membership function approach has been successfully implemented as the default method for fuzzy similarity computation in the thesis codebase. This document summarizes the implementation, performance benefits, and runtime considerations.

## Implementation Details

The per-sensor approach has been integrated as the default implementation in the following ways:

1. In `ClassificationConfig`, the `use_per_sensor` parameter is now set to `True` by default
2. The `compute_window_ndg_membership` function now uses the per-sensor approach by default
3. The `compute_pairwise_similarities` function now delegates to `compute_pairwise_similarities_per_sensor` when `use_per_sensor` is enabled

## Parameter Compatibility

To ensure compatibility between the traditional and per-sensor approaches, the `sigma_method` parameter now supports:

- `"adaptive"`: Uses 10% of the data range as sigma (default)
- `"std"`: Uses standard deviation of the data
- `"range"`: Uses 10% of the data range (equivalent to "adaptive")
- `"iqr"`: Uses interquartile range divided by 2
- Float values: Direct specification of sigma value

## Performance Comparison

Quick tests with a small subset of the Opportunity dataset (300 samples, 3 activities) show:

| Approach | Accuracy | Balanced Accuracy | Macro F1 | Runtime |
|----------|----------|------------------|----------|---------|
| Traditional | 37.5% | 33.3% | 18.2% | ~0s |
| Per-Sensor | 87.5% | 88.9% | 86.7% | 4.27s |

A larger test (900 samples, 3 activities) shows even more dramatic improvements:

| Approach | Accuracy | Balanced Accuracy | Macro F1 | Runtime |
|----------|----------|------------------|----------|---------|
| Traditional | 30.8% | 33.3% | 15.7% | ~0s |
| Per-Sensor | 100.0% | 100.0% | 100.0% | 9.07s |

The per-sensor approach demonstrates significantly better classification performance despite increased computation time.

## Runtime Estimation

Based on our tests:

- Small test (300 samples, 3 activities): 4.27 seconds
- Medium test (900 samples, 3 activities): 9.07 seconds
- Full Opportunity dataset (51,116 samples): Estimated runtime

The runtime scales approximately with:
1. The number of samples (linear relationship)
2. The number of pairwise comparisons (quadratic relationship with the number of windows)

Using the medium test as a baseline:
- Time per sample: 9.07s / 900 = 0.01008 seconds/sample
- Estimated time for full dataset: 0.01008 * 51,116 = 515.3 seconds â‰ˆ 8.6 minutes

However, due to the quadratic complexity of pairwise comparisons, the actual runtime for the full dataset is likely to be much longer. With parallelization using all available cores (assuming 4 cores), we estimate:

- Total runtime: ~7-8 hours for the complete dataset with window size 128
- Memory usage: Moderate to high, depending on window size and number of features

## Recommendations

1. **Use parallelization**: Always use the `n_jobs` parameter to enable parallel processing
2. **Start with small subsets**: For testing new features, use small subsets of the data
3. **Optimize window parameters**: Larger window sizes increase computation time significantly
4. **Consider cloud computing**: For full dataset experiments, consider using cloud computing resources

## Next Steps

1. Implement additional optimizations for the per-sensor approach
2. Explore sparse similarity matrix representations to reduce memory usage
3. Consider GPU acceleration for membership function computation 